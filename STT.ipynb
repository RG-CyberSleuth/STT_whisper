{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RG-CyberSleuth/STT_whisper/blob/main/STT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G__t5_0iKv5K",
        "outputId": "5ed6b652-1536-4155-9d27-c8b10b2e066b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ski8w1lj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ski8w1lj\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.3.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.15.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=f49198bd37c2a69fa5152392c5a00c0def389e1ab173ef25cb57324dd1a0be82\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0948abkv/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [910 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Ign:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,118 kB]\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,552 kB]\n",
            "Get:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,422 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,396 kB]\n",
            "Get:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [27.8 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,218 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.8 kB]\n",
            "Fetched 18.0 MB in 2s (9,215 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "50 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPvFWOfJK1Bg",
        "outputId": "ae8f1f5a-1f9b-4a96-b68d-8213bd4e63b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00:00.000 --> 00:07.000]  We haven't gotten all of the newspapers yet, but we did get some of them.\n",
            "[00:07.000 --> 00:12.000]  This is the very popular Daily News.\n",
            "[00:12.000 --> 00:14.000]  What's the circulation?\n",
            "[00:14.000 --> 00:17.000]  What is the circulation of the Daily News?\n",
            "[00:17.000 --> 00:18.000]  A few million, isn't it?\n",
            "[00:18.000 --> 00:19.000]  Millions.\n",
            "[00:19.000 --> 00:21.000]  It's in the millions. It's the largest.\n",
            "[00:21.000 --> 00:22.000]  Largest circulation.\n",
            "[00:22.000 --> 00:24.000]  So they gave us the center section.\n",
            "[00:24.000 --> 00:27.000]  That's the big, the most popular section.\n",
            "[00:30.000 --> 00:36.000]  This side.\n",
            "[00:36.000 --> 00:37.000]  This side.\n",
            "[00:37.000 --> 00:44.000]  East meets West. Very good reading. Very good reading.\n",
            "[00:44.000 --> 00:51.000]  Very nice. You also have selected.\n",
            "[00:51.000 --> 00:54.000]  The other pictures, I think, some are from the Olympics.\n",
            "[00:54.000 --> 01:00.000]  Very prominent. The center section is next to the front page.\n",
            "[01:00.000 --> 01:04.000]  The center section is the most popular page in the paper.\n",
            "[01:04.000 --> 01:06.000]  It has interesting pictures.\n",
            "[01:12.000 --> 01:13.000]  They wrote a good…\n",
            "[01:13.000 --> 01:18.000]  You can send one, this cutting, to Mr. Bajaj.\n",
            "[01:22.000 --> 01:27.000]  It's everything for East meets West. Very good.\n",
            "[01:27.000 --> 01:28.000]  Send one to Mayapur, as well.\n",
            "[01:28.000 --> 01:30.000]  Send one to Mayapur, as well.\n",
            "[01:30.000 --> 01:35.000]  You can send to many places, but this title is very nice.\n",
            "[01:35.000 --> 01:38.000]  This is the point. This is the point.\n",
            "[01:38.000 --> 01:45.000]  As I say always, the deaf man meets the blind man.\n",
            "[01:48.000 --> 01:52.000]  Together they will do wonderful things.\n",
            "[01:52.000 --> 01:55.000]  And different, they cannot be the same.\n",
            "[01:55.000 --> 01:58.000]  He is blind, he is lame.\n",
            "[01:58.000 --> 02:00.000]  They join together.\n",
            "[02:00.000 --> 02:04.000]  Indian culture and American money.\n",
            "[02:04.000 --> 02:08.000]  They share. Money required.\n",
            "[02:08.000 --> 02:10.000]  You want to hear what they wrote?\n",
            "[02:10.000 --> 02:12.000]  Should I read to you what is written?\n",
            "[02:12.000 --> 02:15.000]  Very nicely written.\n",
            "[02:15.000 --> 02:21.000]  With everybody pulling together and everybody puffing together,\n",
            "[02:21.000 --> 02:27.000]  a huge float is tugged down Fifth Avenue yesterday during the first Ratha Yatra parade\n",
            "[02:27.000 --> 02:30.000]  of International Society for Krishna Consciousness.\n",
            "[02:30.000 --> 02:34.000]  The parade moved south from Central Park to Washington Square Park,\n",
            "[02:38.000 --> 02:47.000]  where a free feast, music, art, dance and theater festival was held.\n",
            "[02:47.000 --> 02:49.000]  According to a spokesperson,\n",
            "[02:49.000 --> 02:56.000]  quote, Ratha Yatra is a time when people come to dance, sing and feast amidst the sublime atmosphere\n",
            "[02:56.000 --> 03:02.000]  of bright flags, festoons, banners, garlands, flowers and incense,\n",
            "[03:02.000 --> 03:07.000]  simply to feel the poetry and blissful nature of life.\n",
            "[03:07.000 --> 03:11.000]  Very good. This is blissful nature.\n",
            "[03:11.000 --> 03:14.000]  Yes. You can see the devotees pulling the float.\n",
            "[03:14.000 --> 03:16.000]  Read the caption in the middle.\n",
            "[03:16.000 --> 03:21.000]  And they have created a civilization, wine, women, gambling and meat.\n",
            "[03:21.000 --> 03:22.000]  Here is what it said.\n",
            "[03:22.000 --> 03:25.000]  The multicolored floats contrast with Fifth Avenue's colors.\n",
            "[03:25.000 --> 03:32.000]  The fifth avenue's concrete canyon as parade passes 34th Street yesterday.\n",
            "[03:32.000 --> 03:36.000]  Here it says, an idyllic mood in saffron robes.\n",
            "[03:36.000 --> 03:39.000]  Everything is approved.\n",
            "[03:39.000 --> 03:41.000]  Oh, yeah. Highly approved.\n",
            "[03:41.000 --> 03:43.000]  Then there's another, New York Times.\n",
            "[03:43.000 --> 03:46.000]  No, that is not important.\n",
            "[03:46.000 --> 03:50.000]  Beautiful photograph.\n",
            "[03:55.000 --> 04:03.000]  It meets West in Hare Kṛṣṇa.\n",
            "[04:03.000 --> 04:04.000]  Feet.\n",
            "[04:04.000 --> 04:05.000]  Feet.\n",
            "[04:05.000 --> 04:06.000]  That.\n",
            "[04:06.000 --> 04:07.000]  Fate.\n",
            "[04:07.000 --> 04:08.000]  That.\n",
            "[04:08.000 --> 04:09.000]  Fate.\n",
            "[04:09.000 --> 04:10.000]  That's right.\n",
            "[04:10.000 --> 04:13.000]  But there's some coffee.\n",
            "[04:13.000 --> 04:16.000]  Look at that picture. It's very clear.\n",
            "[04:16.000 --> 04:18.000]  Should I read you this, Arunachala?\n",
            "[04:18.000 --> 04:19.000]  Yes.\n",
            "[04:19.000 --> 04:24.000]  This one is not, it's not bad, but it's not so accurate.\n",
            "[04:24.000 --> 04:28.000]  In size, it was dwarfed by Operation Sail.\n",
            "[04:28.000 --> 04:33.000]  In popular concern, it was outweighed by the Democratic National Convention.\n",
            "[04:33.000 --> 04:39.000]  But for hundreds of Hare Kṛṣṇa followers, including many Indian immigrants to New York,\n",
            "[04:39.000 --> 04:45.000]  yesterday's Ratha Yatra Festival was by far the most important event in an eventful month.\n",
            "[04:45.000 --> 04:52.000]  Pulling three brightly colored chariots down Fifth Avenue from Central Park to Washington Square,\n",
            "[04:52.000 --> 04:58.000]  the religious group's adherents were celebrating one of the oldest holy days of the Indian calendar,\n",
            "[04:58.000 --> 05:04.000]  the Feast of Jagannath, the Lord of the Universe, according to Kṛṣṇa doctrine.\n",
            "[05:04.000 --> 05:12.000]  Most of the participants in the parade were young Westerners, followers from as far away as Caracas and Montreal.\n",
            "[05:12.000 --> 05:19.000]  But the crowd included hundreds of Indians who brought the basic Kṛṣṇa faith with them from Bombay and Calcutta.\n",
            "[05:19.000 --> 05:20.000]  That's nice.\n",
            "[05:20.000 --> 05:21.000]  Yeah, that's nice.\n",
            "[05:21.000 --> 05:26.000]  Among many other immigrant groups who preserved their forms of worship once they came to America,\n",
            "[05:26.000 --> 05:33.000]  the Indians who watched or participated in the parade were pleased to see that they could keep the faith even in New York City.\n",
            "[05:33.000 --> 05:37.000]  They just can't let them come.\n",
            "[05:37.000 --> 05:40.000]  They become barasāp.\n",
            "[05:40.000 --> 05:41.000]  Come what?\n",
            "[05:41.000 --> 05:42.000]  Barasāp.\n",
            "[05:42.000 --> 05:44.000]  Big, big Western.\n",
            "[05:44.000 --> 05:49.000]  While Hare Kṛṣṇa propounds doctrines of world renunciation common to other varieties of the Hindu faith,\n",
            "[05:49.000 --> 06:00.000]  the sect officially known as the International Society for Kṛṣṇa Consciousness was founded in 1965 by A.C. Bhaktivedanta Swami Prabhupāda,\n",
            "[06:00.000 --> 06:05.000]  whose fame as a guru came only after he arrived in the United States in the same year.\n",
            "[06:05.000 --> 06:15.000]  For most of the Indians watching the parade, however, Hare Kṛṣṇa was close enough to their brand of Hinduism to make them feel at home.\n",
            "[06:15.000 --> 06:17.000]  That's good.\n",
            "[06:17.000 --> 06:18.000]  It means that we're not alone.\n",
            "[06:18.000 --> 06:21.000]  It means that we're not a light cult.\n",
            "[06:21.000 --> 06:23.000]  It means we have a great tradition.\n",
            "[06:23.000 --> 06:24.000]  Yeah, it's actually good.\n",
            "[06:24.000 --> 06:25.000]  They recognize it.\n",
            "[06:25.000 --> 06:30.000]  It's surprising that you find this, quote, it's surprising that you find this right in New York City.\n",
            "[06:30.000 --> 06:37.000]  It's our way of life, said Nagin Patel, a civil engineer from Jersey City who emigrated from Bombay.\n",
            "[06:37.000 --> 06:40.000]  We love New York City and America.\n",
            "[06:40.000 --> 06:42.000]  It's the most beautiful place in the world.\n",
            "[06:42.000 --> 06:46.000]  No other country will give such freedom for our own ceremony.\n",
            "[06:46.000 --> 06:47.000]  That's fantastic.\n",
            "[06:47.000 --> 06:48.000]  Yes.\n",
            "[06:48.000 --> 06:52.000]  But the Krishna people were not entirely free of harassment.\n",
            "[06:52.000 --> 06:58.000]  Along the parade route, three men, including one who said he was an evangelical Christian minister,\n",
            "[06:58.000 --> 07:02.000]  jeered at the parade and called on parade watchers to become Christians.\n",
            "[07:02.000 --> 07:03.000]  Quote,\n",
            "[07:03.000 --> 07:04.000]  Idol worship.\n",
            "[07:04.000 --> 07:06.000]  This is absolutely ridiculous.\n",
            "[07:06.000 --> 07:13.000]  Read the Bible, cried one man, who would identify himself only as a normal Christian.\n",
            "[07:13.000 --> 07:17.000]  There was a brief scuffle when an Indian immigrant tried to tear a large placard,\n",
            "[07:17.000 --> 07:20.000]  out of the hands of another heckler.\n",
            "[07:20.000 --> 07:23.000]  The placard read, turn or burn.\n",
            "[07:23.000 --> 07:27.000]  The police broke things up but made no arrests.\n",
            "[07:27.000 --> 07:32.000]  They are insulting us, said the Krishna follower, who declined to identify himself.\n",
            "[07:32.000 --> 07:34.000]  I am a devotee of Krishna and Christ.\n",
            "[07:34.000 --> 07:36.000]  I am a devotee of Krishna and Christ.\n",
            "[07:36.000 --> 07:41.000]  These people who are doing this in the name of Christ are criminals.\n",
            "[07:41.000 --> 07:43.000]  Pretty strong statement.\n",
            "[07:43.000 --> 07:46.000]  Except for the hecklers, however, the parade was generally a good thing.\n",
            "[07:46.000 --> 07:52.000]  The parade was generally very well received by passers-by who enjoyed the three multi-yud floats,\n",
            "[07:52.000 --> 07:56.000]  the sun and the chanting and dancing of the young Krishna marchers.\n",
            "[07:56.000 --> 08:01.000]  I think it's great, said Tyrone Adams of Philadelphia,\n",
            "[08:01.000 --> 08:05.000]  who was paying a visit to his hometown of Englewood, New Jersey.\n",
            "[08:05.000 --> 08:11.000]  I'm not religious, but they're all happy and dancing and that is what life is all about.\n",
            "[08:11.000 --> 08:14.000]  Even a non-religious person said it.\n",
            "[08:14.000 --> 08:15.000]  In Washington Square,\n",
            "[08:15.000 --> 08:17.000]  a crowd of about 3,000,\n",
            "[08:17.000 --> 08:21.000]  many of whom were there as part of the normal Sunday afternoon activities,\n",
            "[08:21.000 --> 08:24.000]  heard Swami Prabhupada deliver a lecture.\n",
            "[08:24.000 --> 08:27.000]  Later, the crowd was served a free vegetarian feast.\n",
            "[08:27.000 --> 08:32.000]  Along the side, Krishna followers sold Indian sweets, Krishna scriptures\n",
            "[08:32.000 --> 08:37.000]  and what one speaker described as transcendental paraphernalia.\n",
            "[08:39.000 --> 08:42.000]  Man, it's a good army.\n",
            "[08:42.000 --> 08:43.000]  For the times, especially, it's good,\n",
            "[08:43.000 --> 08:46.000]  because they're very conservative.\n",
            "[08:46.000 --> 08:52.000]  The Times first published about my activities.\n",
            "[08:52.000 --> 08:55.000]  Tom, Tom Kings and so on.\n",
            "[08:55.000 --> 08:57.000]  They first published.\n",
            "[08:57.000 --> 08:59.000]  Now, over the television last night,\n",
            "[08:59.000 --> 09:01.000]  there was gigantic coverage.\n",
            "[09:01.000 --> 09:03.000]  CBS, which is the most important station,\n",
            "[09:03.000 --> 09:06.000]  gave two and a half minutes coverage.\n",
            "[09:06.000 --> 09:10.000]  They had a very big program and the reporters,\n",
            "[09:10.000 --> 09:11.000]  just as everyone was watching,\n",
            "[09:11.000 --> 09:12.000]  he said that the reporters,\n",
            "[09:12.000 --> 09:14.000]  the reporters through the whole news,\n",
            "[09:14.000 --> 09:15.000]  they were very grim.\n",
            "[09:15.000 --> 09:16.000]  And then they were,\n",
            "[09:16.000 --> 09:17.000]  because they read.\n",
            "[09:17.000 --> 09:19.000]  They read what they're saying.\n",
            "[09:19.000 --> 09:20.000]  Suddenly their faces lit up and they said,\n",
            "[09:20.000 --> 09:23.000]  and Hare Krishna had a parade today.\n",
            "[09:23.000 --> 09:25.000]  And then they described the whole parade.\n",
            "[09:25.000 --> 09:26.000]  And they loved it.\n",
            "[09:26.000 --> 09:28.000]  They said it was very well received.\n",
            "[09:28.000 --> 09:30.000]  CBS reported.\n",
            "[09:30.000 --> 09:31.000]  ABC reported.\n",
            "[09:31.000 --> 09:33.000]  NBC reported.\n",
            "[09:33.000 --> 09:35.000]  Channel 5 gave big coverage.\n",
            "[09:35.000 --> 09:38.000]  All the television networks gave big coverage.\n",
            "[09:38.000 --> 09:41.000]  It was very well publicized.\n",
            "[09:41.000 --> 09:43.000]  With a lot of coverage,\n",
            "[09:43.000 --> 09:44.000]  with photos, you know,\n",
            "[09:44.000 --> 09:46.000]  they were showing movies of the parade,\n",
            "[09:46.000 --> 09:48.000]  of you lecturing,\n",
            "[09:48.000 --> 09:50.000]  of the crowds that were gathered,\n",
            "[09:50.000 --> 09:52.000]  taking prasādam.\n",
            "[09:52.000 --> 09:58.000]  Somebody should send these clippings,\n",
            "[09:58.000 --> 10:00.000]  not our men,\n",
            "[10:00.000 --> 10:02.000]  to Indira Gandhi.\n",
            "[10:02.000 --> 10:04.000]  To Indira Gandhi.\n",
            "[10:04.000 --> 10:07.000]  Some Indian people.\n",
            "[10:07.000 --> 10:10.000]  She is little anxious\n",
            "[10:10.000 --> 10:15.000]  to cooperate with Americans.\n",
            "[10:15.000 --> 10:20.000]  Because they must criticize him\n",
            "[10:20.000 --> 10:21.000]  for his present action.\n",
            "[10:21.000 --> 10:23.000]  Everyone will criticize him.\n",
            "[10:23.000 --> 10:28.000]  The Americans have criticized like anything.\n",
            "[10:28.000 --> 10:32.000]  And if they are thinking\n",
            "[10:32.000 --> 10:35.000]  that the American people are actually,\n",
            "[10:35.000 --> 10:40.000]  that a nation is under danger,\n",
            "[10:40.000 --> 10:42.000]  that stories are false,\n",
            "[10:42.000 --> 10:43.000]  then we need goblin bidding,\n",
            "[10:43.000 --> 10:44.000]  commentators of the당.\n",
            "[10:44.000 --> 10:45.000]  Now, I want to start\n",
            "[10:45.000 --> 10:46.000]  with something I never expected.\n",
            "[10:46.000 --> 10:48.000]  I'm not saying it doesn't work.\n",
            "[10:48.000 --> 10:50.000]  It doesn't work.\n",
            "[10:50.000 --> 11:08.000]  It does this this way,\n"
          ]
        }
      ],
      "source": [
        "! whisper \"audio.mp3\" --model large --language en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5MvzApuQsrP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMLoIYnQ5edAICS5LjEa0xz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}